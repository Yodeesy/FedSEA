# FedSEA: Structural Entropy Aligned One-Shot Federated Graph Learning via Diffusion
## Abstract
Federated Graph Learning (FGL) offers a privacy-preserving paradigm for collaborative GNN training. However, communication bottlenecks remain a critical challenge in resource-constrained environments. **One-shot FGL** has emerged as a promising solution by restricting communication to a single round, yet existing methods struggle with **Non-IID data heterogeneity** and **generative mode collapse**, often leading to poor generalization.

To overcome these limitations, we introduce **FedSEA**, a novel one-shot framework. Unlike traditional GAN-based approaches, FedSEA employs a **Conditional Diffusion Backbone** enhanced with **Adaptive Layer Normalization (AdaLN)** to synthesize high-fidelity node features with implicit structural coherence. We propose a **Structural Entropy Alignment** mechanism to quantify and leverage client topological complexity, and utilize **Fused Gromov-Wasserstein (FGW)** optimal transport to geometrically align heterogeneous feature spaces. Extensive experiments on standard benchmarks (e.g., Cora) and large-scale datasets (e.g., OGBN-Arxiv) demonstrate that FedSEA achieves state-of-the-art performance in one-shot settings.