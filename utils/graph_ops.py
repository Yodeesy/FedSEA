import torch
import numpy as np
from torch_geometric.data import Data

def softmax_weights(entropy_list, tau=1.0):
    e = np.exp(-np.array(entropy_list) / float(tau))
    w = e / (e.sum() + 1e-12)
    return w.astype(float)


def fuse_graphs(pseudo_graphs, alphas, device=None):
    """
    [Unified Fusion Strategy: Concatenation]
    é€»è¾‘ï¼šå°†æ‰€æœ‰ç”Ÿæˆçš„å­å›¾æ‹¼æ¥æˆä¸€ä¸ªè¶…çº§å¤§å›¾ã€‚
    - Arxiv: èŠ‚ç‚¹æ•°ä» 2w -> 17w (æ¢å¤å…¨å›¾ä¿¡æ¯ï¼Œå…³é”®ï¼)
    - Cora:  èŠ‚ç‚¹æ•°ä» 2k -> 2w  (æ•°æ®å¢å¼ºï¼Œæå‡æ³›åŒ–)
    """
    print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] æ‰§è¡Œæ‹¼æ¥èåˆï¼è¾“å…¥å­å›¾æ•°é‡: {len(pseudo_graphs)}")
    if not pseudo_graphs:
        return None

    if device is None:
        device = pseudo_graphs[0].x.device

    all_x = []
    all_edge_index = []
    all_edge_attr = []

    # åç§»é‡ï¼šç”¨æ¥æŠŠå›¾2æ¥åœ¨å›¾1åé¢ï¼Œè€Œä¸æ˜¯å åœ¨ä¸Šé¢
    current_offset = 0

    for i, g in enumerate(pseudo_graphs):
        # 1. å¿½ç•¥æƒé‡æå°çš„å›¾ (å»å™ª)
        if alphas[i] < 1e-4:
            continue

        # 2. ç‰¹å¾ (Feature)
        x_curr = g.x.to(device)
        all_x.append(x_curr)

        # 3. è¾¹ (Edge Index) - å¿…é¡»åŠ ä¸Šåç§»é‡ï¼
        edge_index = g.edge_index.to(device)
        edge_index_shifted = edge_index + current_offset
        all_edge_index.append(edge_index_shifted)

        # 4. è¾¹æƒé‡ (Edge Weight)
        num_edges = edge_index.size(1)

        # é€»è¾‘ï¼šæˆ‘ä»¬å°† alpha è§†ä¸ºæ ·æœ¬é‡è¦æ€§ã€‚
        # ä¹˜ä»¥ len(pseudo_graphs) æ˜¯ä¸ºäº†ä¿æŒæƒé‡çš„å¹³å‡é‡çº§åœ¨ 1.0 å·¦å³
        scale_factor = float(alphas[i] * len(pseudo_graphs))

        if hasattr(g, 'edge_attr') and g.edge_attr is not None:
            # å¦‚æœç”Ÿæˆå™¨è¾“å‡ºäº†æƒé‡ï¼Œä¿ç•™å¹¶ç¼©æ”¾
            weight = g.edge_attr.view(-1).to(device) * scale_factor
        else:
            # å¦‚æœæ²¡æœ‰æƒé‡ï¼Œé»˜è®¤ä¸º 1.0 å¹¶ç¼©æ”¾
            weight = torch.full((num_edges,), scale_factor, device=device)

        all_edge_attr.append(weight)

        # 5. æ›´æ–°åç§»é‡ (ä¸ºä¸‹ä¸€ä¸ªå›¾åšå‡†å¤‡)
        current_offset += x_curr.size(0)

    # 6. ç‰©ç†æ‹¼æ¥ (Concatenation)
    # è¿™æ­¥ç»å¯¹ä¸ä¼šçˆ†æ˜¾å­˜ï¼Œå› ä¸ºæ˜¯ç¨€ç–æ“ä½œ
    if len(all_x) > 0:
        global_x = torch.cat(all_x, dim=0)
    else:
        return None

    if len(all_edge_index) > 0:
        global_edge_index = torch.cat(all_edge_index, dim=1)
        global_edge_attr = torch.cat(all_edge_attr, dim=0)
    else:
        # æç«¯æƒ…å†µï¼šæ²¡æœ‰ä»»ä½•è¾¹
        global_edge_index = torch.empty((2, 0), dtype=torch.long, device=device)
        global_edge_attr = torch.empty((0,), device=device)

    # è¿”å›æ‹¼æ¥åçš„å¤§å›¾
    return Data(x=global_x, edge_index=global_edge_index, edge_attr=global_edge_attr)